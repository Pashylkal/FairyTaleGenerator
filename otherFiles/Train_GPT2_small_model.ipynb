{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0NLJL5wAhuc"
   },
   "source": [
    "## 1. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oP9v07lj_2BN"
   },
   "outputs": [],
   "source": [
    "!pip install -q aitextgen\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "from aitextgen import aitextgen\n",
    "mount_gdrive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQpi7dRyAprj"
   },
   "source": [
    "##### Move to the folder where the fairy tales file is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5HSNOucARmJ"
   },
   "outputs": [],
   "source": [
    "%cd \"drive/My Drive/GPT-2/fairytales\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D_lBxx6BA9w"
   },
   "source": [
    "##### Define variable with filename to use in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8E7o6J0AV3p"
   },
   "outputs": [],
   "source": [
    "fairytale_file='one_fairytales.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Load model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### if you want to load a default model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ai = aitextgen(tf_gpt2=\"355M\", to_gpu=False, tokenizer_file=tokenizer_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### if you want to load model from checkpoints:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_dir = \"model\"\n",
    "ai = aitextgen(model=f\"{run_dir}/pytorch_model.bin\", config=f\"{run_dir}/config.json\", to_gpu=False, tokenizer_file=tokenizer_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRA8Wbx0BJ2Q"
   },
   "source": [
    "## 3. Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### More information about parameters for training process [you can find here](https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ck9Nq1wTAZcB"
   },
   "outputs": [],
   "source": [
    "ai.train(train_data = fairytale_file,\n",
    "         line_by_line=False,\n",
    "         from_cache=False,\n",
    "         num_steps=10000,\n",
    "         generate_every=1000,\n",
    "         save_every=2000,\n",
    "         save_gdrive=True,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         batch_size=15\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po_w2ACyBVdM"
   },
   "source": [
    "## 4. Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddWdWarAAcMR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ai.generate(n=1,\n",
    "            batch_size=1,\n",
    "            prompt=\"Once upon a time happy frog went to the forest.\",\n",
    "            max_length=300,\n",
    "            min_length = 200)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled23.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}